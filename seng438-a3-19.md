**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#:      | 19    |
| -------------- | --- |
| Student Names: | Alexander Burn    |
|                | William Perks    |
|                | Zohaib Ashfaq    |
|                | Khevin Jugessur   |

(Note that some labs require individual reports while others require one report
for each group. Please see each lab document for details.)

# 1 Introduction

This lab is focused on unit testing with JUnit and Eclipse. Building upon the previous assignment's unit testing focus, we will be using white-box coverage criteria and how to determine the adequacy of a test suite based on its coverage of the code. White-box testing is a critical aspect of software engineering. This lab will help with necessary skills to measure test adequacy based on completeness defined by the portion of the code which is exercised. By the end of this lab, we will be able to use code coverage tools, design test cases to improve code coverage, understand the benefits and drawbacks of measuring test adequacy with code coverage tools, and calculate data-flow coverage by hand.

# 2 Manual data-flow coverage calculations for X and Y methods

Text…

# 3 A detailed description of the testing strategy for the new unit test

Text…

# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

Text…

# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

Range:

<img src="Img_A3/R1.png" alt="Img_A3/R1.png" width="360"/>
<img src="Img_A3/R2.png" alt="Img_A3/R2.png" width="360"/>
<img src="Img_A3/R3.png" alt="Img_A3/R3.png" width="360"/>
<img src="Img_A3/R4.png" alt="Img_A3/R4.png" width="360"/>
<img src="Img_A3/R5.png" alt="Img_A3/R5.png" width="360"/>
<img src="Img_A3/R6.png" alt="Img_A3/R6.png" width="360"/>
<img src="Img_A3/R7.png" alt="Img_A3/R7.png" width="360"/>
<img src="Img_A3/R8.png" alt="Img_A3/R8.png" width="360"/>
<img src="Img_A3/R9.png" alt="Img_A3/R9.png" width="360"/>
<img src="Img_A3/R10.png" alt="Img_A3/R10.png" width="360"/>

<br>
Line Coverage:
<img src="Img_A3/RL.png" alt="Img_A3/RL.png" width="360"/>

<br>
 
Branch Coverage:
<img src="Img_A3/RB.png" alt="Img_A3/RB.png" width="360"/>
<br>

Method Coverage:
<img src="Img_A3/RM.png" alt="Img_A3/RM.png" width="360"/>
<br>

For Range, the three different coverages we used were: Branch, Line, and Method.  For eclipse, there was no option for Statement coverage so we used Line instead.  Similarly, eclipse did not have an option for Condition coverage so we used Method instead.  For Branch coverage we got an overall value of 96.3%, for Line coverage we got an overall coverage of 92.4%, for Method coverage we got an overall coverage of 100.0%.

# 6 Pros and Cons of coverage tools used and Metrics you report

The major coverage tool used in this lab was EclEmma which is built into the Eclipse IDE. It was very helpful in reporting the percentage of coverage each test was capable of. It was able to generate the reports in regards to the coverage for statement, branch, and condition. Some cons of this tool are that it only works with Java. Another is that it takes time for bigger coding files. Also, just because the test coverage shows a high percentage of coverage does not mean the code is bug free.

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Creating tests to ensure that the software complies with the requirements listed in the project documentation is known as requirements-based test generation. This strategy makes sure the product has the functionality users want, but it might not test every part of the code. On the other side, coverage-based test generation concentrates on developing tests that guarantee that each line of code is performed. This strategy might lead to more thorough testing, but it might not guarantee that the software satisfies all requirements. Requirements-based test creation has the benefit of guaranteeing that the software has the needed functionality and is frequently more time and resource efficient. However, the potential for overlooking critical edge situations and potential inconsistencies between the published requirements and the actual code implementation are drawbacks of requirements-based test generation, though. More thorough testing and discovering sections of code that are not tested are two benefits of coverage-based test generation. Nevertheless, the drawbacks of coverage-based test generation include the potential for redundant tests and the risk for missing crucial functional requirements. The decision between these strategies ultimately comes down to the particular requirements of the project and the objectives of the testing.

# 8 A discussion on how the team work/effort was divided and managed

The team managed to complete the assignment successfully by working with a mixture of online and in person meetings. We began developing our test design plan together to inquire everyone in the group’s opinion on how we should approach our plan. First, we had a meeting over Discord to set up Eclipse and all the external libraries. We then met together to discuss which of the methods we would decide to do. Then, we divided the methods fairly for coding the JUnit Test after doing a detailed test plan. We will monitor each other's progress through Discord and we met on Thursday the 9th of February to review all test cases and their documentation.

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

Starting this lab took a while initially. This is because the importing of the files and libraries took a while. In addition, the hamcrest file for Assignment 3 was corrupted so we then had to use the file from Assignment 2. The group members were ultimately able to figure out how to get all files for the project. It also took a small portion of the group members time to understand how the converge tool worked. Once everything was figured out thanks to one of the group members and explaining to everyone else, the rest of the assignment was done easily.

# 10 Comments/feedback on the lab itself

While the lab handout was explanatory and easy enough to follow, the Hamcrest file being corrupt stood as an obstacle for the group. In the future, it would be helpful if one of the course instructors could make the correction earlier on.
