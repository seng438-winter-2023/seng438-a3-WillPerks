**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#:      | 19    |
| -------------- | --- |
| Student Names: | Alexander Burn    |
|                | William Perks    |
|                | Zohaib Ashfaq    |
|                | Khevin Jugessur   |

(Note that some labs require individual reports while others require one report
for each group. Please see each lab document for details.)

# 1 Introduction

This lab is focused on unit testing with JUnit and Eclipse. Building upon the previous assignment's unit testing focus, we will be using white-box coverage criteria and how to determine the adequacy of a test suite based on its coverage of the code. White-box testing is a critical aspect of software engineering. This lab will help with necessary skills to measure test adequacy based on completeness defined by the portion of the code which is exercised. By the end of this lab, we will be able to use code coverage tools, design test cases to improve code coverage, understand the benefits and drawbacks of measuring test adequacy with code coverage tools, and calculate data-flow coverage by hand.

# 2 Manual data-flow coverage calculations for X and Y methods

<img src="Img_A3/Img2.png" alt="Img_A3/Img2.png" width="360"/>

<img src="Img_A3/Img3.png" alt="Img_A3/Img3.png" width="360"/>

<img src="Img_A3/Img4.png" alt="Img_A3/Img4.png" width="360"/>

getUpperBound():

<img src="Img_A3/Img1.png" alt="Img_A3/Img1.png" width="360"/>

Def-use sets per statement:
DEF[1] = {}, USE[1] = {}
DEF[2] = {msg}, USE[2] = {msg}
DEF[3] = {}, USE[3] = {}

DU-pairs per variable:
For msg: (2,2)

Pairs covered per test case:
Test case:  upperBoundShouldBeOne()
Pairs covered: (2,2)

DU-pair coverage:
CUc = 1
CUf = 0
CU = 1
PUc = 2
PUf = 0
PU = 2

(1 + 2)/[(1 + 2) - (0 + 0)] = 100%


# 3 A detailed description of the testing strategy for the new unit test

In the beginning of this assignment, we used the EclEmma tool to test the coverage of the initial code. After viewing this information, the group then had to figure out a way to get the tests to increase the coverage percentage. We decided to then split the tests for the classes among the group. We work mainly in pairs (Khevin, Alex and Will, Zohaib) to work on DataUtilities and Range class testing. Khevin and Alex worked primarily on DataUtilities and part of Range class testing. Will and Zohaib worked primarily on Range class testing. The testing strategy that we decided to use on the assignment was to observe the coverage information that we have regarding the two classes and to develop test cases in conjunction with looking at the code we are testing (whitebox testing). The coverage information allowed us to view the branch, line, method and overall coverage in conjunction with the code we are testing to determine how to approach each method specifically. Certain methods required more branch coverage as the methods contained more branches, therefore we focused on developing more tests to cover all the possible branches in those methods. Methods with low line coverage required us to develop more tests to cover more of the lines of code within the methods. We used method coverage instead as there is no condition coverage in EclEmma.


The coverage percentage before we improved our tests were the following:

Range.java:

Line: 4.0%  
Method: 25.0%  
Branch: 4.0%

DataUtilities.java:

Line: 20.6%
Method:50.0%
Branch: 22.3%


# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

factorByTwo()
This increases the Branch coverage.  It does this by testing to see if scale correctly branches when given a correct value to factor by.

forValidRanges()
This increases the Branch coverage by testing to see if equals returns true when given two identical ranges.

containsInRange()
This increases the Condition coverage by testing to see if contains return true when given a value that is within the given range.

constrainForValueInRange()
This increases the Condition coverage by testing to see if constrain returns 0 when given a value that is within the given range. 

forRangesWithFirstRangeNull()
This increases the Statement coverage by testing to see if combine tests to see if both ranges are not null.


# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

Range:

<img src="Img_A3/R1.png" alt="Img_A3/R1.png" width="360"/>
<img src="Img_A3/R2.png" alt="Img_A3/R2.png" width="360"/>
<img src="Img_A3/R3.png" alt="Img_A3/R3.png" width="360"/>
<img src="Img_A3/R4.png" alt="Img_A3/R4.png" width="360"/>
<img src="Img_A3/R5.png" alt="Img_A3/R5.png" width="360"/>
<img src="Img_A3/R6.png" alt="Img_A3/R6.png" width="360"/>
<img src="Img_A3/R7.png" alt="Img_A3/R7.png" width="360"/>
<img src="Img_A3/R8.png" alt="Img_A3/R8.png" width="360"/>
<img src="Img_A3/R9.png" alt="Img_A3/R9.png" width="360"/>
<img src="Img_A3/R10.png" alt="Img_A3/R10.png" width="360"/>

<br/>
Line Coverage:
<br/>
<img src="Img_A3/RL.png" alt="Img_A3/RL.png" width="360"/>

<br/>
 
Branch Coverage:
<br/>
<img src="Img_A3/RB.png" alt="Img_A3/RB.png" width="360"/>
<br/>

Method Coverage:
<br/>
<img src="Img_A3/RM.png" alt="Img_A3/RM.png" width="360"/>
<br/>

For Range, the three different coverages we used were: Branch, Line, and Method.  For eclipse, there was no option for Statement coverage so we used Line instead.  Similarly, eclipse did not have an option for Condition coverage so we used Method instead.  For Branch coverage we got an overall value of 96.3%, for Line coverage we got an overall coverage of 92.4%, for Method coverage we got an overall coverage of 100.0%.

# 6 Pros and Cons of coverage tools used and Metrics you report

The major coverage tool used in this lab was EclEmma which is built into the Eclipse IDE. It was very helpful in reporting the percentage of coverage each test was capable of. It was able to generate the reports in regards to the coverage for statement, branch, and condition. Some cons of this tool are that it only works with Java. Another is that it takes time for bigger coding files. Also, just because the test coverage shows a high percentage of coverage does not mean the code is bug free.

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Creating tests to ensure that the software complies with the requirements listed in the project documentation is known as requirements-based test generation. This strategy makes sure the product has the functionality users want, but it might not test every part of the code. On the other side, coverage-based test generation concentrates on developing tests that guarantee that each line of code is performed. This strategy might lead to more thorough testing, but it might not guarantee that the software satisfies all requirements. Requirements-based test creation has the benefit of guaranteeing that the software has the needed functionality and is frequently more time and resource efficient. However, the potential for overlooking critical edge situations and potential inconsistencies between the published requirements and the actual code implementation are drawbacks of requirements-based test generation, though. More thorough testing and discovering sections of code that are not tested are two benefits of coverage-based test generation. Nevertheless, the drawbacks of coverage-based test generation include the potential for redundant tests and the risk for missing crucial functional requirements. The decision between these strategies ultimately comes down to the particular requirements of the project and the objectives of the testing.

# 8 A discussion on how the team work/effort was divided and managed

The team managed to complete the assignment successfully by working with a mixture of online and in person meetings. We began developing our test design plan together to inquire everyone in the group’s opinion on how we should approach our plan. First, we had a meeting over Discord to set up Eclipse and all the external libraries. We then met together to discuss which of the methods we would decide to do. Then, we divided the methods fairly for coding the JUnit Test after doing a detailed test plan. We will monitor each other's progress through Discord and we met on Thursday the 9th of February to review all test cases and their documentation.

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

Starting this lab took a while initially. This is because the importing of the files and libraries took a while. In addition, the hamcrest file for Assignment 3 was corrupted so we then had to use the file from Assignment 2. The group members were ultimately able to figure out how to get all files for the project. It also took a small portion of the group members time to understand how the converge tool worked. Once everything was figured out thanks to one of the group members and explaining to everyone else, the rest of the assignment was done easily.

# 10 Comments/feedback on the lab itself

While the lab handout was explanatory and easy enough to follow, the Hamcrest file being corrupt stood as an obstacle for the group. In the future, it would be helpful if one of the course instructors could make the correction earlier on.
